{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Transfer learning using MobileNetV3\n",
    "\n",
    "In the field of machine learning, transfer learning is a powerful technique that leverages pre-trained models and applies them to new tasks. This approach allows us to save time and computational resources by reusing the knowledge gained from training on large datasets.\n",
    "\n",
    "In this exercise we use MobileNetV3, a convolutional neural network architecture for mobile devices, to train a classifier for the Fashion-MNIST dataset using the PyTorch framework.\n",
    "\n",
    "Fashion-MNIST is a drop-in replacement for MNIST (images of size 28x28 with 10 classes) but instead of hand-written digits it contains tiny images of clothes!\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Load the Fashion-MNIST dataset using the torchvision package.\n",
    "2. Define a PyTorch model using the MobileNetV3 architecture.\n",
    "3. Train the model on the Fashion-MNIST dataset.\n",
    "4. Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Fashion-MNIST dataset\n",
    "\n",
    "The torchvision package provides access to popular datasets, model architectures, and image transformations for computer vision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:03<00:00, 7.08MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 159kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:01<00:00, 2.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 11.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Fashion-MNIST dataset\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def load_data(batch_size, data_dir=\"data\"):\n",
    "    \"\"\"Load the Fashion-MNIST dataset.\"\"\"\n",
    "\n",
    "    # Define transforms to normalize the data\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "    )\n",
    "\n",
    "    # Download and load the training data\n",
    "    trainset = datasets.FashionMNIST(\n",
    "        data_dir, download=True, train=True, transform=transform\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Download and load the test data\n",
    "    testset = datasets.FashionMNIST(\n",
    "        data_dir, download=True, train=False, transform=transform\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "trainloader, testloader = load_data(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to create functions that will help us work with the labels when they're a little more complicated than the handwritten digits 0-9. Let's create those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_index=0, class_name=T-shirt/top\n",
      "class_index=1, class_name=Trouser\n",
      "class_index=2, class_name=Pullover\n",
      "class_index=3, class_name=Dress\n",
      "class_index=4, class_name=Coat\n",
      "class_index=5, class_name=Sandal\n",
      "class_index=6, class_name=Shirt\n",
      "class_index=7, class_name=Sneaker\n",
      "class_index=8, class_name=Bag\n",
      "class_index=9, class_name=Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# Define some helper functions to helps with the labels\n",
    "def get_class_names():\n",
    "    \"\"\"Return the list of classes in the Fashion-MNIST dataset.\"\"\"\n",
    "    return [\n",
    "        \"T-shirt/top\",\n",
    "        \"Trouser\",\n",
    "        \"Pullover\",\n",
    "        \"Dress\",\n",
    "        \"Coat\",\n",
    "        \"Sandal\",\n",
    "        \"Shirt\",\n",
    "        \"Sneaker\",\n",
    "        \"Bag\",\n",
    "        \"Ankle boot\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_class_name(class_index):\n",
    "    \"\"\"Return the class name for the given index.\"\"\"\n",
    "    return get_class_names()[class_index]\n",
    "\n",
    "\n",
    "def get_class_index(class_name):\n",
    "    \"\"\"Return the class index for the given name.\"\"\"\n",
    "    return get_class_names().index(class_name)\n",
    "\n",
    "\n",
    "for class_index in range(10):\n",
    "    print(f\"class_index={class_index}, class_name={get_class_name(class_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to inspect your data before you use it to train a model just to know everything is fine. You know what they say: garbage in, garbage out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show 10 images from the training set with their labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()  # convert from tensor to numpy array\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # transpose dimensions\n",
    "\n",
    "\n",
    "images, labels = next(iter(trainloader))  # get the first batch\n",
    "\n",
    "# show images with labels\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plot_size = 10\n",
    "\n",
    "for idx in np.arange(plot_size):\n",
    "    ax = fig.add_subplot(2, plot_size // 2, idx + 1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(get_class_name(int(labels[idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Define a PyTorch model using the MobileNetV3 architecture.\n",
    "\n",
    "The `torchvision.models.mobilenet_v3_large` class provides access to pre-trained MobileNetV3 model. We can use the model and replace the final layer with a fully-connected layer with 10 outputs since we have 10 classes. We can then freeze the weights of the convolutional layers and train only the new fully-connected layer.\n",
    "\n",
    "Let's start with inspecting the original MobileNetV3 (small version) first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssingla/miniconda3/envs/3.12env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ssingla/miniconda3/envs/3.12env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /Users/ssingla/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100%|██████████| 9.83M/9.83M [00:00<00:00, 11.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Conv2dNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained MobileNetV3 and inspect its structure\n",
    "import torchvision.models as models\n",
    "\n",
    "mobilenet_v3_model = models.mobilenet_v3_small(pretrained=True)\n",
    "print(mobilenet_v3_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the `classifier` section of the model.\n",
    "\n",
    "```\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
    "    (1): Hardswish()\n",
    "    (2): Dropout(p=0.2, inplace=True)\n",
    "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
    "  )\n",
    "```\n",
    "\n",
    "There are 1000 output features, but our dataset does not have that many. See if you can complete the next cell so that it has the right number of output nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (model): MobileNetV3(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "      (1): Hardswish()\n",
      "      (2): Dropout(p=0.2, inplace=True)\n",
      "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssingla/miniconda3/envs/3.12env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ssingla/miniconda3/envs/3.12env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# Define a model class that extends the nn.Module class\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "\n",
    "        # Load the pre-trained MobileNetV3 (Small) architecture\n",
    "        self.model = models.mobilenet_v3_small(pretrained = True)\n",
    "\n",
    "        # Replace the last fully-connected layer with a new one of the right size\n",
    "        self.model.classifier[3] = nn.Linear(1024, 10)\n",
    "\n",
    "        # Freeze all the weights of the network except for the last fully-connected layer\n",
    "        self.freeze()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert 1x28x28 input tensor to 3x28x28 tensor, to convert it to a color image\n",
    "        x = x.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Resize the input to 224x224, since MobileNetV3 (Small) expects images of that size\n",
    "        if x.shape[2:] != (224, 224):\n",
    "            x = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Forward pass\n",
    "        return self.model(x)\n",
    "\n",
    "    def freeze(self):\n",
    "        # Freeze all the weights of the network except for the last fully-connected layer\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze the final layer\n",
    "        for param in self.model.classifier[3].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all the weights of the network\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "# Create an instance of the MobileNetV3 model\n",
    "model = MobileNetV3()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Train the model on the MNIST dataset\n",
    "\n",
    "We can train the model using the standard PyTorch training loop. For the loss function, we'll use CrossEntropyLoss. We also use the Adam optimizer with a learning rate of 0.002. We train the model for 1 epoch so we can see how the model performs after just one pass of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose our device automatically (CPU, GPU, or MPS) and write our training loop!\n",
    "\n",
    "The MPS backend is for M1/M2/etc Macs.\n",
    "\n",
    "If you are having any errors running the code locally, you should try to use the `cpu` mode manually, i.e. `device = torch.device(\"cpu\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set the device as GPU, MPS, or CPU according to availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Batch [1/938], Loss: 2.4301\n",
      "Epoch [1/1], Batch [101/938], Loss: 0.4466\n",
      "Epoch [1/1], Batch [201/938], Loss: 0.5401\n",
      "Epoch [1/1], Batch [301/938], Loss: 0.3594\n",
      "Epoch [1/1], Batch [401/938], Loss: 0.4697\n",
      "Epoch [1/1], Batch [501/938], Loss: 0.4093\n",
      "Epoch [1/1], Batch [601/938], Loss: 0.3836\n",
      "Epoch [1/1], Batch [701/938], Loss: 0.4153\n",
      "Epoch [1/1], Batch [801/938], Loss: 0.4600\n",
      "Epoch [1/1], Batch [901/938], Loss: 0.4124\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "# Create a PyTorch training loop\n",
    "\n",
    "model = model.to(device)  # Move the model weights to the device\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch_num, (images, labels) in enumerate(trainloader):\n",
    "        # Move tensors to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate the loss and perform backprop\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss for every 100th iteration\n",
    "        if (batch_num) % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}\".format(\n",
    "                    epoch + 1, epochs, batch_num + 1, len(trainloader), loss.item()\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Evaluate the model on the test set\n",
    "\n",
    "We evaluate the model on the test set by:\n",
    "* printing the accuracy\n",
    "* plotting a few examples of correct and incorrect predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Mismatched Tensor types in NNPack convolutionOutput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# torch.max return both max and argmax. We get the argmax here.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m, in \u001b[0;36mMobileNetV3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py:220\u001b[0m, in \u001b[0;36mMobileNetV3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py:210\u001b[0m, in \u001b[0;36mMobileNetV3._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 210\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    213\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/3.12env/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Mismatched Tensor types in NNPack convolutionOutput"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "# Print the loss and accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0\n",
    "\n",
    "for images, labels in testloader:\n",
    "    # Move tensors to the configured device\n",
    "    images.to(device)\n",
    "    labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss += loss_fn(outputs, labels)\n",
    "\n",
    "    # torch.max return both max and argmax. We get the argmax here.\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\n",
    "    \"Test Accuracy of the model on the test images: {} %\".format(100 * correct / total)\n",
    ")\n",
    "print(\"Test Loss of the model on the test images: {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a few examples of correct and incorrect predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the first batch of images and labels\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "# Move tensors to the configured device\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Plot the images with labels, at most 10\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "for idx in np.arange(min(10, len(images))):\n",
    "    ax = fig.add_subplot(2, 10 // 2, idx + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images.cpu()[idx]))\n",
    "    ax.set_title(\n",
    "        \"{} ({})\".format(get_class_name(predicted[idx]), get_class_name(labels[idx])),\n",
    "        color=(\"green\" if predicted[idx] == labels[idx] else \"red\"),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
